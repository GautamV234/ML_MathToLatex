{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_baseline1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9GzktvslE6oe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,in_channels = 1):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = in_channels,out_channels = 64,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 64,out_channels = 128 ,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.conv3 = nn.Conv2d(in_channels = 128,out_channels = 256 ,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.conv4 = nn.Conv2d(in_channels = 256,out_channels = 512 ,kernel_size=(3,3),padding=(1,1),stride=(1,1))\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=(2,2),padding=(0,0),stride=(2,2))\n",
        "    self.max_pool2 = nn.MaxPool2d(kernel_size=(2,1),padding=(0,0),stride=(2,1))\n",
        "    # self.batch_norm = nn.BatchNorm2d()\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.conv3(x)\n",
        "    # x = nn.BatchNorm2d(256*7*7) \n",
        "    # x = self.conv3(x)\n",
        "    x = self.max_pool(x)\n",
        "    x = self.conv4(x)\n",
        "    # x = nn.BatchNorm2d(x)\n",
        "# TODO - Add the Positional Encodings \n",
        "# https://github.com/tatp22/multidim-positional-encoding\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super(Decoder,self).__init__()\n"
      ],
      "metadata": {
        "id": "U74maWbrqLpH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(in_channels=1)\n",
        "x = torch.randn(64,1,28,28)\n",
        "print(x.shape)\n",
        "x=encoder(x)\n",
        "print(x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYBxUj1qa17o",
        "outputId": "419d4b46-75a8-4056-9419-a9f7efe0898d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 4608])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "input = np.arange(1,8).reshape(-1,1)\n",
        "print(input.shape)\n",
        "input = torch.tensor(input, dtype=torch.float)\n",
        "print(input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EE_gmw1g3ur",
        "outputId": "de4357fd-2180-4043-b448-f7656838c32e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 1)\n",
            "torch.Size([7, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u6Cj1NCfQbON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}